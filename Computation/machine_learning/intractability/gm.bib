% This file was created with JabRef 2.6.
% Encoding: Cp1252

@ARTICLE{Bre14,
  author = {Bresler, Guy},
  title = {{Efficiently learning Ising models on arbitrary graphs}},
  archiveprefix = {arXiv},
  arxivid = {1411.6156v2},
  eprint = {1411.6156v2},
  file = {:C$\backslash$:/Users/Owner/Dropbox/Math/Computation/machine\_learning/intractability/1411.6156.pdf:pdf}
}

@INCOLLECTION{Gam13,
  author = {Gamarnik, David},
  title = {{Correlation decay method for decision, optimization, and inference
	in large-scale networks}},
  booktitle = {Tutorials in Operations Research, Vol. 10},
  year = {2013},
  number = {April 2015},
  pages = {108--121},
  doi = {http://dx.doi.org/10.1287/educ.2013.0119},
  file = {:C$\backslash$:/Users/Owner/Dropbox/Math/Computation/machine\_learning/intractability/correlation decay.pdf:pdf},
  isbn = {9780984337842},
  keywords = {graphical models,local algorithms,long-range independence,networks}
}

@ARTICLE{SW12,
  author = {Santhanam, Narayana P. and Wainwright, Martin J.},
  title = {{Information-theoretic limits of selecting binary graphical models
	in high dimensions}},
  journal = {IEEE Transactions on Information Theory},
  year = {2012},
  volume = {58},
  pages = {4117--4134},
  number = {7},
  abstract = {The problem of graphical model selection is to correctly estimate
	the graph structure of a Markov random field given samples from the
	underlying distribution. We analyze the information-theoretic limitations
	of the problem of graph selection for binary Markov random fields
	under high-dimensional scaling, in which the graph size \$p\$ and
	the number of edges \$k\$, and/or the maximal node degree \$d\$ are
	allowed to increase to infinity as a function of the sample size
	\$n\$. For pairwise binary Markov random fields, we derive both necessary
	and sufficient conditions for correct graph selection over the class
	\$\backslash mathcal\{G\}\_\{p,k\}\$ of graphs on \$p\$ vertices
	with at most \$k\$ edges, and over the class \$\backslash mathcal\{G\}\_\{p,d\}\$
	of graphs on \$p\$ vertices with maximum degree at most \$d\$. For
	the class \$\backslash mathcal\{G\}\_\{p, k\}\$, we establish the
	existence of constants \$c\$ and \$c'\$ such that if \$\backslash
	numobs < c k \backslash log p\$, any method has error probability
	at least 1/2 uniformly over the family, and we demonstrate a graph
	decoder that succeeds with high probability uniformly over the family
	for sample sizes \$\backslash numobs > c' k\^{}2 \backslash log p\$.
	Similarly, for the class \$\backslash mathcal\{G\}\_\{p,d\}\$, we
	exhibit constants \$c\$ and \$c'\$ such that for \$n < c d\^{}2 \backslash
	log p\$, any method fails with probability at least 1/2, and we demonstrate
	a graph decoder that succeeds with high probability for \$n > c'
	d\^{}3 \backslash log p\$.},
  archiveprefix = {arXiv},
  arxivid = {0905.2639},
  doi = {10.1109/TIT.2012.2191659},
  eprint = {0905.2639},
  file = {:C$\backslash$:/Users/Owner/Dropbox/Math/Computation/machine\_learning/intractability/info theoretic limits of gm.pdf:pdf},
  issn = {00189448},
  keywords = {High dimensional inference,KL divergence between Ising models,Markov
	random fields,sample complexity,structure of Ising models}
}

